---
# Display name
title: 汪旭鸿

# Name pronunciation (optional)
# name_pronunciation: Wang Hsü-Hung 

# Full name (for SEO)
first_name: Xuhong
last_name: Wang

# # Pronouns (optional)
# pronouns: she/her

# Status emoji
status:
  icon: ☕️

# Is this the primary user of the site?
superuser: true

# Highlight the author in author lists? (true/false)
highlight_name: true

# Role/position/tagline
role: Assistant Researcher

# Organizations/Affiliations to display in Biography blox
organizations:
  - name: Shanghai AI Laboratory
    url: https://www.shlab.org.cn/

# Social network links
# Need to use another icon? Simply download the SVG icon to your `assets/media/icons/` folder.
profiles:
  - icon: at-symbol
    url: 'mailto:wangxuhong@pjlab.org.cn'
    label: E-mail Me wangxuhong@pjlab.org.cn
  # - icon: brands/x
  #   url: https://twitter.com/GetResearchDev
  # - icon: brands/instagram
  #   url: https://www.instagram.com/
  - icon: brands/github
    url: https://github.com/WangXuhongCN
  # - icon: brands/linkedin
  #   url: https://www.linkedin.com/
  - icon: academicons/google-scholar
    url: https://scholar.google.com/citations?user=qBfqJbcAAAAJ&hl=en
  - icon: academicons/orcid
    url: https://orcid.org/0000-0002-0944-8667

interests:
  - Mutli-model Large Language Model
  - Self-evolving Memory System
  - Reinforcement Learning with Environment Feedback

education:
  - area: PhD Artificial Intelligence
    institution: Shanghai Jiao Tong University
    date_start: 2017-09-01
    date_end: 2022-09-30
    summary: |
      My PhD research focuses on designing novel graph neural networks for modeling industry-level dynamic networks, such as knowledge graphs, social networks, and financial networks. Thesis on *Deep graph learning based anomaly detection and dynamic relation modeling*. 
    button:
      text: 'Read Thesis'
      url: uploads/thesis.pdf
  - area: BSc Electronices Engineering
    institution: Sichuan University
    date_start: 2013-09-01
    date_end: 2017-06-30
    # summary: |
    #   GPA: 3.6/4.0

work:
  - position: Assistant Researcher
    company_name: Shanghai Artificial Intelligence Laboratory
    company_url: 'https://www.shlab.org.cn/'
    company_logo: ''
    date_start: 2022-10-08
    date_end: ''
    summary: |2-
      Main Project:
      - LLM Safety Evaluating System
      - Large-scale LLM Agents System
      - LLM evovlving Sandbox
  - position: Applied Scientist (Intern)
    company_name: Amazon Web Services
    company_url: 'https://aws.amazon.com/cn/'
    company_logo: ''
    date_start: 2021-02-01
    date_end: 2021-11-30
    summary: |
      The team is responsible for maintaining Deep Graph Learning (DGL), the world's most widely used graph learning framework. I focused on improving models for dynamic graph neural network algorithms.

# Skills
# Add your own SVG icons to `assets/media/icons/`
# skills:
#   - name: Technical Skills
#     items:
#       - name: Python
#         description: ''
#         percent: 80
#         icon: code-bracket
#       - name: Data Science
#         description: ''
#         percent: 100
#         icon: chart-bar
#       - name: SQL
#         description: ''
#         percent: 40
#         icon: circle-stack
#   - name: Hobbies
#     color: '#eeac02'
#     color_border: '#f0bf23'
#     items:
#       - name: Hiking
#         description: ''
#         percent: 60
#         icon: person-simple-walk
#       - name: Cats
#         description: ''
#         percent: 100
#         icon: cat
#       - name: Photography
#         description: ''
#         percent: 80
#         icon: camera

# languages:
#   - name: English
#     percent: 100
#   - name: Chinese
#     percent: 75
#   - name: Portuguese
#     percent: 25

# Awards.
#   Add/remove as many awards below as you like.
#   Only `title`, `awarder`, and `date` are required.
#   Begin multi-line `summary` with YAML's `|` or `|2-` multi-line prefix and indent 2 spaces below.
awards:
  - title: Neural Networks and Deep Learning
    url: https://www.coursera.org/learn/neural-networks-deep-learning
    date: '2023-11-25'
    awarder: Coursera
    icon: coursera
    summary: |
      I studied the foundational concept of neural networks and deep learning. By the end, I was familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.
  - title: Blockchain Fundamentals
    url: https://www.edx.org/professional-certificate/uc-berkeleyx-blockchain-fundamentals
    date: '2023-07-01'
    awarder: edX
    icon: edx
    summary: |
      Learned:
      - Synthesize your own blockchain solutions
      - Gain an in-depth understanding of the specific mechanics of Bitcoin
      - Understand Bitcoin’s real-life applications and learn how to attack and destroy Bitcoin, Ethereum, smart contracts and Dapps, and alternatives to Bitcoin’s Proof-of-Work consensus algorithm
  - title: 'Object-Oriented Programming in R'
    url: https://www.datacamp.com/courses/object-oriented-programming-with-s3-and-r6-in-r
    certificate_url: https://www.datacamp.com
    date: '2023-01-21'
    awarder: datacamp
    icon: datacamp
    summary: |
      Object-oriented programming (OOP) lets you specify relationships between functions and the objects that they can act on, helping you manage complexity in your code. This is an intermediate level course, providing an introduction to OOP, using the S3 and R6 systems. S3 is a great day-to-day R programming tool that simplifies some of the functions that you write. R6 is especially useful for industry-specific analyses, working with web APIs, and building GUIs.
---

## About Me

Xuhong Wang is an assistant researcher at the Shanghai Artificial Intelligence Laboratory. He graduated from Sichuan University with a Bachelor's degree in 2017, and obtained his Ph.D. from the Shanghai Jiao Tong University in 2022. His main research focus during his doctoral studies was graph learning and knowledge mining. Recently, his research focuses on training self-evolving LLMs by utilizing an interactive feedback environment and a parameterized memory system.
